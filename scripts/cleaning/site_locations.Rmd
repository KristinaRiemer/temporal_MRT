---
title: "Compile all site coordinates"
output:
  html_notebook: default
  pdf_document: default
---

```{r}
library(raster)
library(dplyr)
```

#### TODO

* Get latitude and longitude for each dataset's site
* Document source for each of these

```{r}
site_locations = data.frame()
```
Create empty dataframe that will store location values. 

### Site 1: Portal

Notes

* From [Ernest et al., 2016](https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1890/15-2115.1)
* Couldn't find location information in retriever versions of Portal data
* Expect Portal to be about -109.063, 31.9107
* In UTM zone 12

#### TODO 

* Add test for UTM to lat/lon conversion?

```{r}
if(!file.exists("../../data/portal/raw/Portal_UTMCoords.csv")){
  download.file("https://esajournals.onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1890%2F15-2115.1&file=ecy1360-sup-0001-DataS1.zip", 
               "../../data/portal/raw/ecy1360-sup-0001-datas1.zip")
  unzip("../../data/portal/raw/ecy1360-sup-0001-datas1.zip", 
        exdir = "../../data/portal/raw/")
}
```
Download data containing Portal coordinates. 
```{r}
portal_coords = read.csv("../../data/portal/raw/Portal_UTMCoords.csv")
```
Read in particular dataset with coordinates. 
```{r}
portal_mean_UTM = SpatialPoints(cbind(mean(portal_coords$east), mean(portal_coords$north)), 
                                proj4string = CRS("+proj=utm +zone=12 +datum=WGS84"))
portal_mean_latlon = as.data.frame(spTransform(portal_mean_UTM, CRS("+proj=longlat +datum=WGS84")))
```
Generate variables for each coordinate direction, then convert from UTM to lat/lon. 
```{r}
site_locations = site_locations %>% 
  bind_rows(c(site_name = "portal", 
              lon = portal_mean_latlon$coords.x1, 
              lat = portal_mean_latlon$coords.x2))
site_locations
```
Add Portal lat/lon to locations dataframe. 

### Site 2: Fray Jorge

Notes

* From "Materials and Methods" section in Aguilera et al. (2016)
![](../../fray_jorge_location.png)
* Expect latitude to be -30ish and longitude to be -71ish

#### TODO

* Find second source for Fray Jorge coordinates
* Figure out why coordinates are in ocean on temp grid

```{r}
deg_min_sec_to_dec = function(degree, minute, second, direction = NULL){
  decimal_degree = degree + (minute * (1/60)) + (second * (1/60) * (1/60))
  if(direction == "S" | direction == "W"){
    decimal_degree = -decimal_degree
  }
  return(decimal_degree)
}
```
Function to convert degree minute second coordinates to decimal degrees. 
```{r}
fray_jorge_lat = deg_min_sec_to_dec(30, 38, 0, "S")
fray_jorge_lon = deg_min_sec_to_dec(71, 40, 0, "W")
```
Use function to convert Fray Jorge coordinates. 
```{r}
site_locations = site_locations %>% 
  bind_rows(c(site_name = "frayjorge", 
              lon = fray_jorge_lon, 
              lat = fray_jorge_lat))
site_locations
```
Add converted Fray Jorge coordinates to locations dataframe. 


### Site 3: Sevilleta

Notes

* From [LTER data download site for Sev](https://portal.lternet.edu/nis/metadataviewer?packageid=knb-lter-sev.8.297972)
* In Temporal, Geographic and Taxonomic Coverage section
* Have decimal degree longitudes and latitudes for all 8 sites

```{r}
sevilleta_coords_all = data.frame(longitudes = c(-106.736, -106.736, -106.927, -106.927, -107.03, -106.535, -106.523, -106.631), latitudes = c(34.3331, 34.3331, 34.296, 34.269, 34.418, 34.368, 34.4146, 34.3348))
```
Get all longitudes and latitudes. 
```{r}
site_locations = site_locations %>% 
  bind_rows(c(site_name = "sevilleta", 
              lon = mean(sevilleta_coords_all$longitudes), 
              lat = mean(sevilleta_coords_all$latitudes)))
site_locations
```
Add average Sevilleta coordinates to locations dataframe. 
```{r}
site_locations$lon = as.numeric(site_locations$lon)
site_locations$lat = as.numeric(site_locations$lat)
```
Change coordinates columns to numeric type. 

### Save coordinates dataframe

```{r}
write.csv(site_locations, "../../data/site_locations.csv", row.names = FALSE)
```
Save locations dataframe as csv. 